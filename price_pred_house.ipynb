{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVs0sPdISIZJ8rgZQbV+sI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farzad-mos/House_price_pred/blob/main/price_pred_house.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# House price prediction according to the house features\n",
        "A\tsimple\tyet\tchallenging\tproject,\tto\tpredict\tthe\thousing\tprice\tbased\ton\tcertain\tfactors\tlike\thouse\tarea, bedrooms,\tfurnished,\tnearness\tto\tmainroad,\tetc.\tThe\tdataset\tis\tsmall\tyet,\tit's\tcomplexity\tarises\tdue\tto the\tfact\tthat\tit\thas\tstrong\tmulticollinearity."
      ],
      "metadata": {
        "id": "KVaykilTetGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1-Import libreires and datasets"
      ],
      "metadata": {
        "id": "iMNGkybDe3Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from\tpandas\timport\tread_csv,\tDataFrame,\tconcat\n",
        "from\tmatplotlib.pyplot\timport\tshow,\tsuptitle,\tsubplots_adjust,\ttight_layout,\tsubplots,scatter\n",
        "from\tmatplotlib.pyplot\timport\tfigure,\ttitle,\txlabel,\tylabel,\tgrid,\txticks,\ttight_layout\n",
        "from\tnumpy\timport\tnan,log,inf\n",
        "from\tseaborn\timport\tkdeplot,\theatmap,\thistplot,\tboxplot,\tcountplot, scatterplot,kdeplot,lmplot,lineplot,violinplot,\n",
        "from\tsklearn.model_selection\timport\ttrain_test_split\n",
        "from\tsklearn.linear_model\timport\tLinearRegression,\tRidge\n",
        "from\txgboost\timport\tXGBRegressor\n",
        "from\tsklearn.metrics\timport\tr2_score,\tmean_squared_error,\tmean_absolute_error\n",
        "from\tmath\timport\tsqrt\n",
        "from\tpickle\timport\tdump\n",
        "from\tsklearn.preprocessing\timport\tLabelEncoder label\t=\tLabelEncoder()\n",
        "\n",
        "import\twarnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\",\tcategory=DeprecationWarning)\n",
        "\n",
        "# import datasets\n",
        "df_train\t=\tread_csv(\"train.csv\")"
      ],
      "metadata": {
        "id": "2P53iff7e3G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- Exploratory\tData\tAnalysis\t(EDA)\n",
        "Initial\tData\tUnderstandings:\n",
        "* Data\tloading\tand\tInspection\n",
        "* Data\tTypes\n",
        "* Missing\tValues\n",
        "* Duplicates\n",
        "* Check basic statistics;\n",
        "  * Summary\tStatistical:\t`describe()`\n",
        "  * counts: `value_counts()`\n",
        "* Check data types; `select_dtypes()`\n",
        "* Stats preview plots (Histogram: `hist`, KDE: `kdeplot`)\n"
      ],
      "metadata": {
        "id": "3XbZgGpQi3o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the data outline\n",
        "df_train.head()\n",
        "# check data size\n",
        "print(f'shape_train:\t{df_train.shape}')\n",
        "# check data info (if there is nan values and missing data)\n",
        "df_train.info()\n",
        "# check the columns name\n",
        "df_train.columns\n",
        "\n",
        "# find missing data\n",
        "for\ti\tin\tdf_train.columns:\n",
        "  print(i,\"\t:\t\",df_train[i].isnull().sum()) #check missing values\n",
        "\n",
        "# check duplicated data\n",
        "df_train.duplicated().sum()\n",
        "\n",
        "# basic stats\n",
        "df_train.describe().T\n",
        "\n",
        "# data type\n",
        "df_train.select_dtypes(include='object').describe()\n",
        "\n",
        "# plot hist of columns\n",
        "df_train.drop('Id',axis=1).hist(bins=15,\tfigsize=(20,\t16),\tcolor='red',\n",
        "                                edgecolor='black')\n",
        "suptitle('Histograms\tof\tColumns',\tfontsize=16)\n",
        "subplots_adjust(hspace=0.5)\n",
        "show()\n",
        "\n",
        "# value counts\n",
        "df_train['YearRemodAdd'].value_counts()\n",
        "\n",
        "# unique years\n",
        "df_train['YearRemodAdd'].unique()\n",
        "\n",
        "# plot KDE\n",
        "figure(figsize=(12,\t4))\n",
        "kdeplot(df_train['SalePrice'],\tfill=True,\tcolor='blue',\talpha=0.6)\n",
        "title(f'Kernel\tDensity\tEstimate(KDE)\t-\tSale\tPrice', fontsize=16)\n",
        "xlabel('Sale\tPrice',\tfontsize=12)\n",
        "ylabel('Density',\tfontsize=12)\n",
        "grid(True,\tlinestyle='--',\talpha=0.7)\n",
        "tight_layout()\n",
        "show()\n"
      ],
      "metadata": {
        "id": "GwVefB1cjYLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3- Feature engineering\n",
        "  * feature correlation by heatmap plot (Heatmap: `heatmap`)\n",
        "  * extract high corrolated features\n"
      ],
      "metadata": {
        "id": "cAoJCJS2neE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering\n",
        "\n",
        "# check corrolation between features by heatmap\n",
        "figure(figsize=(35,\t20))\n",
        "heatmap(df_train.select_dtypes(include='number').corr(),\tannot=True)\n",
        "show()\n",
        "\n",
        "#\tfunction\tto\textract\thigh\tpositive\tcorrelated\tcolumns\n",
        "def\tget_high_corr(df_train,\tthreshold):\n",
        "  corr\t=\tdf_train.select_dtypes('number').corr()\n",
        "  high_corr\t=\tcorr[(corr\t>=\tthreshold)\t&\t(corr\t!=\t1.000)]\n",
        "  high_corr\t=\thigh_corr.dropna(how='all',\taxis=1).dropna(how='all',\taxis=0)\n",
        "  return\thigh_corr\n",
        "  #\tget\thigh\tpositive\tcorrelated\tcolumns\n",
        "  high_corr\t=\tget_high_corr(df_train,\t0.7)\n",
        "  #\tplot\thigh\tpositive\tcorrelated\tcolumns\n",
        "  figure(figsize=(15,\t5))\n",
        "  plot\t=\theatmap(high_corr,\tannot=True,\tcmap='coolwarm')\n",
        "  plot.set_title('High\tPositive\tCorrelation')\n",
        "  show()\n",
        "\n",
        "#\tfunction\tto\textract\thigh\tpositive\tcorrelated\tcolumns\n",
        "def\tget_high_corr(df_train,\tthreshold):\n",
        "  corr\t=\tdf_train.select_dtypes('number').corr()\n",
        "  high_corr\t=\tcorr[(corr\t<=\tthreshold)\t&\t(corr\t!=\t1.000)]\n",
        "  high_corr\t=\thigh_corr.dropna(how='all',\taxis=1).dropna(how='all',\taxis=0)\n",
        "  return\thigh_corr\n",
        "  #\tget\thigh\tpositive\tcorrelated\tcolumns\n",
        "  high_corr\t=\tget_high_corr(df_train,\t-0.38)\n",
        "  #\tplot\thigh\tpositive\tcorrelated\tcolumns\n",
        "  figure(figsize=(14,\t4))\n",
        "  plot\t=\theatmap(high_corr,\tannot=True,\tcmap='coolwarm')\n",
        "  plot.set_title('High\tPositive\tCorrelation')\n",
        "  show()"
      ],
      "metadata": {
        "id": "HjlasRfdnq7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4- Data Cleaning and Data Relations"
      ],
      "metadata": {
        "id": "OVOC4_fzo6Ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# handling missing values and duplications\n",
        "for\ti\tin\tdf_train.columns:\n",
        "  print(i,\"\t:\t\",df_train[i].isnull().sum())\n",
        "\n",
        "  #\tsum\tof\tnulls\t>=\t30\n",
        "  for\tall\tdatafor\tcolumn\tin\tdf_train.columns:\n",
        "    SumOfNulls\t=\tdf_train[column].isnull().sum()\n",
        "    if\tSumOfNulls\t>\t30:\n",
        "      print(f'{column}\t:\t{SumOfNulls}')\n",
        "\n",
        "\n",
        "df_train\t=\tdf_train.drop(['Id','EnclosedPorch','BsmtHalfBath','LowQualFinSF',\n",
        "  'MiscFeature','Fence','PoolQC','Fireplac' ,'3SsnPorch','ScreenPorch',\n",
        "  'PoolArea','MiscVal','MiscVal','BsmtFinSF2','Fireplaces'],axis=1)\n",
        "df_train\t=\tdf_train.dropna()\n",
        "df_train.shape\n",
        "\n",
        "df_train.head()\n",
        "df_train['WoodDeckSF'].value_counts()\n",
        "df_train['OpenPorchSF'].value_counts()\n",
        "df_train['MasVnrArea'].value_counts()\n",
        "\n",
        "\n",
        "#\ttransform\tfrom\tflaot\tto\tint\n",
        "df_train['MasVnrArea']\t=\tdf_train['MasVnrArea'].astype(int)\n",
        "df_train['MasVnrArea'].value_counts()\n",
        "df_train['WoodDeckSF'].mean()\n",
        "df_train['MasVnrArea'].mean()\n",
        "\n",
        "#\treplace\t0\twirh\t'nan'\tfor\ttrain\tdata\n",
        "df_train['WoodDeckSF']\t=\tdf_train['WoodDeckSF'].replace(0,nan)\n",
        "df_train['OpenPorchSF']\t=\tdf_train['OpenPorchSF'].replace(0,nan)\n",
        "df_train['MasVnrArea']\t=\tdf_train['MasVnrArea'].replace(0,nan)\n",
        "\n",
        "#\tReplace\t'nan'\twith\tmean\n",
        "mean_WoodDeckSF\t=\tdf_train['WoodDeckSF'].mean()\n",
        "df_train['WoodDeckSF'].fillna(mean_WoodDeckSF,inplace=True)\n",
        "mean_OpenPorchSF\t=\tdf_train['OpenPorchSF'].mean()\n",
        "df_train['OpenPorchSF'].fillna(mean_OpenPorchSF,inplace=True)\n",
        "mean_MasVnrArea\t=\tdf_train['MasVnrArea'].mean()\n",
        "df_train['MasVnrArea'].fillna(mean_MasVnrArea,inplace=True)\n",
        "\n",
        "# Outlier detection and removal\n",
        "df_train['SalePrice'].describe()\n",
        "\n",
        "fig.axes\t=\tsubplots(nrows=1,ncols=1)\n",
        "fig.set_size_inches(8,\t6)\n",
        "boxplot(data=df_train,y=\"SalePrice\",orient=\"v\",ax=axes)\n",
        "axes.set(ylabel='SalePrice',title=\"Box\tPlot\tOn\tSaleprice\")\n",
        "show()\n",
        "\n",
        "# Distribution\n",
        "figure(figsize=(14,\t6))\n",
        "histplot(df_train['SalePrice'],\tbins=50,\tkde=True,\tcolor='red')\n",
        "title('Distribution\tof\tSale\tPrice')\n",
        "xlabel('Sale\tPrice')\n",
        "ylabel('count')\n",
        "show()\n",
        "print(f\"\\nSkewness\tof\tPrice:\t{df_train['SalePrice'].skew():.2f}\")\n",
        "print(f\"Kurtosis\tof\tPrice:\t{df_train['SalePrice'].kurt():.2f}\")\n",
        "\n",
        "# Scattering\n",
        "figure(figsize=(14,\t6))\n",
        "scatterplot(x='LotArea',\ty='SalePrice',\tdata=df_train)\n",
        "title('Relationship\tbetween\tSale\tPrice\tand\tArea')\n",
        "xlabel('Area')\n",
        "ylabel('Sale\tPrice')\n",
        "show()\n",
        "\n",
        "# Data relation (Jointplot)\n",
        "figure(figsize=(14,\t4))\n",
        "jointplot(x='LotArea',\ty='SalePrice',\tdata=df_train,\tkind='reg',\theight=8,\tscatter_kws={'alpha':0.3})\n",
        "suptitle('Relationship\tbetween\tSale\tprice\tand\tArea',\ty=1.02,\tfontsize=16) s\n",
        "how()\n",
        "\n",
        "# trend detection\n",
        "figure(figsize=(14,\t6))\n",
        "regplot(x='YearBuilt',\ty='SalePrice',\tdata=df_train,\tscatter_kws={'alpha':0.3},\tline_kws={'color':'red'})\n",
        "title('Relationship\tbetween\tyear\tbuilt\tand\tsale\tprice',\tfontsize=16)\n",
        "xlabel('Year\tBuilt',\tfontsize=12)\n",
        "ylabel('Sale\tPrice',\tfontsize=12)\n",
        "show()\n",
        "\n",
        "# Feature (no. of rooms) distribution\n",
        "figure(figsize=(14,\t5))\n",
        "countplot(x='TotRmsAbvGrd',\tdata=df_train,\tpalette='viridis')\n",
        "title('Distribution\tof\tnumber\tof\trooms',\tfontsize=16)\n",
        "xlabel('Number\tof\trooms',\tfontsize=12)\n",
        "ylabel('Count',\tfontsize=12)\n",
        "show()\n",
        "\n",
        "# Feature Density\t(between\tnumber\tof\trooms\tand\tsale\tprice)\n",
        "jointplot(x='TotRmsAbvGrd',\ty='SalePrice',\tdata=df_train,\tkind='kde',\theight=8,\tcmap='viridis')\n",
        "suptitle('Density\tbetween\tnumber\tof\trooms\tand\tsale\tprice',\ty=1.02,\tfontsize=16)\n",
        "show()\n",
        "\n",
        "# Feature distribution\n",
        " #1- house style\n",
        "figure(figsize=(14,\t5))\n",
        "countplot(x='HouseStyle',\tdata=df_train,\tpalette='viridis')\n",
        "title('Distribution\tof\thouse\tstyle',\tfontsize=16)\n",
        "xlabel('House\tstyle',\tfontsize=12)\n",
        "ylabel('Count',\tfontsize=12)\n",
        "show()\n",
        "\n",
        " #2- type\tof\tbuilding\n",
        "figure(figsize=(14,\t5))\n",
        "df_train['BldgType'].value_counts().plot(kind='bar',\tcolor=['green','yellow','blue','red','orange'])\n",
        "title('Number\tof\ttype\tof\tbuilding',\tfontsize=16)\n",
        "xlabel('Type\tof\tbuilding',\tfontsize=12)\n",
        "ylabel('Count',\tfontsize=12)\n",
        "xticks(rotation=45)\n",
        "show()\n",
        "\n",
        "\n",
        " #3- Type of building vs. Sale price\n",
        "figure(figsize=(14,\t6))\n",
        "violinplot(x='BldgType',\ty='SalePrice',\tdata=df_train,\tpalette=['green','yellow','blue','red','orange'])\n",
        "title('Type\tof\tbuilding\tby\tSale\tprice',\tfontsize=16)\n",
        "xlabel('Type\tof\tbuilding',\tfontsize=12)\n",
        "ylabel('Sale\tprice',\tfontsize=12)\n",
        "show()\n",
        "\n",
        " #4- Log sale price\n",
        "figure(figsize=(14,\t6))\n",
        "histplot(log(df_train['SalePrice']).replace(-inf,1e-6),\tbins=50,\tkde=True,\tcolor='green')\n",
        "title('Distribution\tof\tlog\tSale\tPrice')\n",
        "xlabel('Log\tSale\tPrice')\n",
        "ylabel('count')\n",
        "show()\n",
        "print(f\"\\nSkewness\tof\tPrice:\t{log(df_train['SalePrice']).replace(-inf,1e-6).skew():.2f}\")\n",
        "\n",
        "# Feature trends (sale/yr.)\n",
        "avg_price_by_year\t=\tdf_train.groupby('YearBuilt')['SalePrice'].mean()\n",
        "figure(figsize=(14,\t6))\n",
        "lineplot(x=avg_price_by_year.index,\ty=avg_price_by_year.values,\tmarker='o',\tcolor='purple')\n",
        "title('Avg\tof\tsale\tprice\tby\tyear\tbuilt',\tfontsize=16)\n",
        "xlabel('Year\tbuilt',\tfontsize=12)\n",
        "ylabel('Avg\tof\tsale\tprice',\tfontsize=12)\n",
        "grid(True)\n",
        "show()\n",
        "\n",
        "# Relationship between area and sale price by No. room\n",
        "figure(figsize=(12,\t8))\n",
        "lmplot(x='LotArea',\ty='log_SalePrice',\thue='TotRmsAbvGrd',\tdata=df_train,\n",
        "       col='TotRmsAbvGrd',\tcol_wrap=3,\theight=4,\taspect=1.2,\n",
        "       scatter_kws={'alpha':0.4})\n",
        "suptitle('Relationship\tbetween\tArea\tand\tsale\tprice\tby\tnumber\tof\trooms',\n",
        "         y=1.05,\tfontsize=18)\n",
        "show()"
      ],
      "metadata": {
        "id": "CI3rftbbpBvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5- Data Transformation & Spliting"
      ],
      "metadata": {
        "id": "1E9d5uQswaTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check data type to transform from str. to int.\n",
        "train_obj\t=\tdf_train.select_dtypes(include='object')\n",
        "train_obj.shape\n",
        "train_non_obj\t=\tdf_train.select_dtypes(exclude='object')\n",
        "train_non_obj.shape\n",
        "\n",
        "\n",
        "for\tcol\tin\ttrain_obj.columns:\n",
        "  print(f'{col}\t:\t{train_obj[col].nunique()}')\n",
        "\n",
        "\n",
        "for col\tin\ttrain_obj.columns:\n",
        "    nuniques\t=\ttrain_obj[col].nunique()\n",
        "    if\tnuniques\t==\t3:\n",
        "      print(f'{col}\t:\t{train_obj[col].nunique()}')\n",
        "\n",
        "\n",
        "#### Transformations:\n",
        "\n",
        " #\tLandSlope:\tSlope\tof\tproperty\n",
        " #\tGtl\t(Gentle)\n",
        " #\tMod\t(Moderate)\n",
        " #\tSev\t(Severe)\t\tt\n",
        " rain_obj['LandSlope'].value_counts()\t#\tordinal\n",
        "\n",
        " # pi plot of LandShape\n",
        " train_obj['LandSlope'].value_counts().plot.pie(autopct='%0.2f%%')\n",
        " show()\n",
        "\n",
        " # Transform data type: change landshape to no.\n",
        " train_obj['LandSlope']=\ttrain_obj['LandSlope'].replace('Gtl',1)\n",
        " train_obj['LandSlope']=\ttrain_obj['LandSlope'].replace('Mod',2)\n",
        " train_obj['LandSlope']=\ttrain_obj['LandSlope'].replace('Sev',3)\n",
        " train_obj['LandSlope'].value_counts() #check number of data per group\n",
        "\n",
        "\n",
        " #\tGarageFinish:\tInterior\tfinish\tof\tthe\tgarage\n",
        " #\tUnf\t(Unfinished)\n",
        " #\tRFn\t(Rough\tFinished)\n",
        " #\tFin\t(Finished)\n",
        " train_obj['GarageFinish'].value_counts()\t#\tordinal\n",
        "\n",
        " # pi plot of GarageFinish\n",
        " train_obj['GarageFinish'].value_counts().plot.pie(autopct='%0.2f%%') show()\n",
        "\n",
        " # Transform data type: change GarageFinish to no.\n",
        " train_obj['GarageFinish']=\ttrain_obj['GarageFinish'].replace('Unf',1)\n",
        " train_obj['GarageFinish']=\ttrain_obj['GarageFinish'].replace('RFn',2)\n",
        " train_obj['GarageFinish']=\ttrain_obj['GarageFinish'].replace('Fin',3)\n",
        " train_obj['GarageFinish'].value_counts() #check number of data per group\n",
        "\n",
        " #\tPavedDrive:\tPaved\tdriveway\n",
        " #\tY\t(Yes\tPaved)\n",
        " #\tP\t(Partially\tPaved)\n",
        " #\tN\t(Not\tPaved)\n",
        " train_obj['PavedDrive'].value_counts()\t#\tordinal\n",
        "\n",
        " # pi plot of PaveDrive\n",
        " train_obj['PavedDrive'].value_counts().plot.pie(autopct='%0.2f%%')\n",
        " show()\n",
        "\n",
        " # Transform data type: change Pavedrive to No.\n",
        "train_obj['PavedDrive']=\ttrain_obj['PavedDrive'].replace('Y',1)\n",
        "train_obj['PavedDrive']=\ttrain_obj['PavedDrive'].replace('N',2)\n",
        "train_obj['PavedDrive']=\ttrain_obj['PavedDrive'].replace('P',3)\n",
        "train_obj['PavedDrive'].value_counts() #check number of data per group\n",
        "\n",
        "\n",
        "#\tLotShape\t:\tGeneral\tshape\tof\tproperty\n",
        "#\tReg\t(Regular)\n",
        "#\tIR1\t(Slightly\tirregular)\n",
        "#\tIR2\t(Moderately\tirregular)\n",
        "#\tIR3\t(Irregular)\n",
        "train_obj['LotShape'].value_counts()\t#\tordinal\n",
        "\n",
        "# pi plot of LotShape\n",
        "train_obj['LotShape'].value_counts().plot.pie(autopct='%0.2f%%')\n",
        "show()\n",
        "\n",
        "# Transform data\n",
        "train_obj['LotShape']=\ttrain_obj['LotShape'].replace('Reg',1)\n",
        "train_obj['LotShape']=\ttrain_obj['LotShape'].replace('IR1',2)\n",
        "train_obj['LotShape']=\ttrain_obj['LotShape'].replace('IR2',3)\n",
        "train_obj['LotShape']=\ttrain_obj['LotShape'].replace('IR3',4)\n",
        "train_obj['LotShape'].value_counts()\n",
        "\n",
        "#\tLandContour\t:\tFlatness\tof\tthe\tproperty\n",
        "#\tLvl\t(Level)\n",
        "#\tBnk\t(Banked\t–\tSlope\tfrom\tthe\tstreet)\n",
        "#\tHLS\t(Hillside\t–\tSignificant\tslope)\n",
        "#\tLow\t(Depression\t–\tBelow\tstreet\tlevel)\n",
        "train_obj['LandContour'].value_counts()\t#\tordinal\n",
        "\n",
        "train_obj['LandContour'].value_counts().plot.pie(autopct='%0.2f%%')\n",
        "show()\n",
        "\n",
        "train_obj['LandContour']=\ttrain_obj['LandContour'].replace('Lvl',1)\n",
        "train_obj['LandContour']=\ttrain_obj['LandContour'].replace('Bnk',2)\n",
        "train_obj['LandContour']=\ttrain_obj['LandContour'].replace('HLS',3)\n",
        "train_obj['LandContour']=\ttrain_obj['LandContour'].replace('Low',4)\n",
        "\n",
        "train_obj['LandContour'].value_counts()\n",
        "\n",
        "#\tExterQual:\tExterior\tmaterial\tquality\n",
        "#\tFa\t(Fair)\n",
        "#\tTA\t(Typical/Average)\n",
        "#\tGd\t(Good)\n",
        "#\tEx\t(Excellent)\n",
        "train_obj['ExterQual'].value_counts()\t#\tordinal\n",
        "\n",
        "train_obj['ExterQual'].value_counts().plot.pie(autopct='%0.2f%%')\n",
        "show()\n",
        "\n",
        "train_obj['ExterQual']=\ttrain_obj['ExterQual'].replace('Fa',1)\n",
        "train_obj['ExterQual']=\ttrain_obj['ExterQual'].replace('TA',2)\n",
        "train_obj['ExterQual']=\ttrain_obj['ExterQual'].replace('Gd',3)\n",
        "train_obj['ExterQual']=\ttrain_obj['ExterQual'].replace('Ex',4)\n",
        "train_obj['ExterQual'].value_counts()\n",
        "\n",
        "#\tExterCond:\tPresent\tcondition\tof\tthe\tmaterial\ton\tthe\texterior\n",
        "#\tFa\t(Fair)\n",
        "#\tTA\t(Typical/Average)\n",
        "#\tGd\t(Good)\n",
        "#\tEx\t(Excellent)\n",
        "train_obj['ExterCond'].value_counts()\t#\tordinal\n",
        "\n",
        "countplot(x='ExterCond',\tdata=df_train)\n",
        "show()\n",
        "\n",
        "train_obj['ExterCond']=\ttrain_obj['ExterCond'].replace('Fa',1)\n",
        "train_obj['ExterCond']=\ttrain_obj['ExterCond'].replace('TA',2)\n",
        "train_obj['ExterCond']=\ttrain_obj['ExterCond'].replace('Gd',3)\n",
        "train_obj['ExterCond']=\ttrain_obj['ExterCond'].replace('Ex',4)\n",
        "train_obj['ExterCond'].value_counts()\n",
        "\n",
        "#\tBsmtCond\t:\tGeneral\tcondition\tof\tthe\tbasement\n",
        "#\tGd\t(Good)\n",
        "#\tTA\t(Typical/Average)\n",
        "#\tFa\t(Fair)\n",
        "#\tPo\t(Poor)\n",
        "train_obj['BsmtCond'].value_counts()\t#\tordinal\n",
        "\n",
        "train_obj['BsmtCond'].value_counts().plot.pie(autopct='%0.2f%%')\n",
        "show()\n",
        "\n",
        "train_obj['BsmtCond']=\ttrain_obj['BsmtCond'].replace('Gd',1)\n",
        "train_obj['BsmtCond']=\ttrain_obj['BsmtCond'].replace('TA',2)\n",
        "train_obj['BsmtCond']=\ttrain_obj['BsmtCond'].replace('Fa',3)\n",
        "train_obj['BsmtCond']=\ttrain_obj['BsmtCond'].replace('Po',4)\n",
        "train_obj['BsmtCond'].value_counts()\n",
        "\n",
        "\n",
        "#\tBsmtQual:\tHeight\tof\tthe\tbasement\n",
        "#\tFa\t(Fair)\n",
        "#\tTA\t(Typical/Average)\n",
        "#\tGd\t(Good)\n",
        "#\tEx\t(Excellent)\n",
        "train_obj['BsmtQual'].value_counts()\t#\tordinal\n",
        "\n",
        "train_obj['BsmtQual'].value_counts().plot.pie(autopct='%0.2f%%')\n",
        "show()\n",
        "\n",
        "train_obj['BsmtQual']=\ttrain_obj['BsmtQual'].replace('Fa',1)\n",
        "train_obj['BsmtQual']=\ttrain_obj['BsmtQual'].replace('TA',2)\n",
        "train_obj['BsmtQual']=\ttrain_obj['BsmtQual'].replace('Gd',3)\n",
        "train_obj['BsmtQual']=\ttrain_obj['BsmtQual'].replace('Ex',4)\n",
        "\n",
        "train_obj['BsmtQual'].value_counts()\n",
        "\n",
        "\n",
        "#\tBsmtExposure\t:\tWalkout\tor\tgarden\tlevel\tbasement\twalls\n",
        "#\tNo\n",
        "#\tMn\t(Minimum)\n",
        "#\tAv\t(Average)\n",
        "#\tGd\t(Good)\n",
        "train_obj['BsmtExposure'].value_counts()\t#\tordinal\n",
        "\n",
        "train_obj['BsmtExposure'].value_counts().plot.pie(autopct='%0.2f%%')\n",
        "show()\n",
        "\n",
        "train_obj['BsmtExposure']=\ttrain_obj['BsmtExposure'].replace('No',1)\n",
        "train_obj['BsmtExposure']=\ttrain_obj['BsmtExposure'].replace('Mn',2)\n",
        "train_obj['BsmtExposure']=\ttrain_obj['BsmtExposure'].replace('Av',3)\n",
        "train_obj['BsmtExposure']=\ttrain_obj['BsmtExposure'].replace('Gd',4)\n",
        "train_obj['BsmtExposure'].value_counts()\n",
        "\n",
        "\n",
        "# check transformed data\n",
        "train_data\t=\tconcat([train_non_obj,train_obj],axis=1)\n",
        "train_data.info()\n",
        "\n",
        "\n",
        "train_obj2\t=\ttrain_data.select_dtypes(include='object')\n",
        "train_non_obj2\t=\ttrain_data.select_dtypes(exclude='object')\n",
        "\n",
        "\n",
        "# check label Encoder\n",
        "\n",
        "for\ti\tin\trange(0,train_obj2.shape[1]):\n",
        "  train_obj2.iloc[:,i]=label.fit_transform(train_obj2.iloc[:,i])\n",
        "\n",
        "\n",
        "train_obj2\t=\ttrain_obj2.astype(int)\n",
        "train_obj2.info()\n",
        "\n",
        "# final transformed & encoded data\n",
        "final_train_data\t=\tconcat([train_non_obj2,train_obj2],axis=1)\n",
        "\n",
        "final_train_data['LotShape'].value_counts()\n",
        "final_train_data['KitchenQual'].value_counts()\n",
        "\n",
        "\n",
        "### Data spliting\n",
        "X=\tfinal_train_data.drop(['SalePrice'],axis=1)\n",
        "y=\tfinal_train_data['SalePrice']\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,y,train_size=0.8,random_state=1234)\n",
        "\n",
        "print(x_train.shape,\tx_test.shape)\n",
        "print(y_train.shape,\ty_test.shape)"
      ],
      "metadata": {
        "id": "r-6GzaCKwd_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6- Model Definition, Training & Comparision\n",
        "3 models have been defined:\n",
        "* Ridge\n",
        "* Linear Regression\n",
        "* XGBRegression"
      ],
      "metadata": {
        "id": "regG7_u68j0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_2=[]\n",
        "mse\t=[]\n",
        "rmse=[]\n",
        "mae=[]\n",
        "def\treg(model):\n",
        "  model.fit(x_train,y_train)\n",
        "  pred\t=\tmodel.predict(x_test)\n",
        "  R2\t=\tr2_score(y_test,pred)\n",
        "  MSE\t=\tmean_squared_error(y_test,pred)\n",
        "  RMSE\t=\tsqrt(mean_squared_error(y_test,pred))\n",
        "  MAE\t=\tmean_absolute_error(y_test,pred)\n",
        "  r_2.append(R2)\n",
        "  mse.append(MSE)\n",
        "  rmse.append(RMSE)\n",
        "  mae.append(MAE)\n",
        "\n",
        "# models\n",
        "Ridge_model\t=\tRidge()\n",
        "LinearRegression_model\t=\tLinearRegression()\n",
        "XGBRegressor_model\t=\tXGBRegressor()\n",
        "\n",
        "Algorithms\t=\t['LinearRegression','Ridge','XGBRegressor']\n",
        "\n",
        "\n",
        "reg(LinearRegression_model)\n",
        "reg(Ridge_model)\n",
        "reg(XGBRegressor_model)\n",
        "\n",
        "# fitting results comparision\n",
        "result\t=\tDataFrame({'Algorithms':Algorithms,'R2':r_2,'mse':mse,'rmse':rmse,'mae':mae})\n"
      ],
      "metadata": {
        "id": "cxYpTVnh9Gyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Comparision:\n",
        "\n",
        "* XGBRegressor\tstands\tout\tas\tthe\tbest-performing\talgorithm\tamong\tthe\tthree:\n",
        " * It\thas\tthe\thighest\tR2\tvalue\t(0.88448),\tindicating\tthat\tit\texplains\ta\tsignificantly\tlarger\tproportion\tof\tthe\tvariance\tin\tthe\ttarget\tvariable compared\tto\tLinear\tRegression\tand\tRidge.\n",
        " * It\thas\tthe\tlowest\tmse\t(811,541,568.0),\trmse\t(28,487.57),\tand\tmae\t(18,410.43),\twhich\tmeans\tits\tpredictions\thave\tthe\tsmallest average\terrors.\n",
        "* Linear\tRegression\tand\tRidge\tperform\tvery\tsimilarly:\n",
        " * Their\tR2\tvalues\tare\talmost\tidentical\t(around\t0.847).\n",
        " * Their\tmse,\trmse,\tand\tmae\tvalues\tare\talso\tvery\tclose,\tindicating\tsimilar\tlevels\tof\tprediction\terror.\tRidge's\tmae\tis\tslightly\tlower\tthan Linear\tRegression's,\tbut\tthe\tdifference\tis\tminimal."
      ],
      "metadata": {
        "id": "KjM4QPgD-DZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comparision visualization\n",
        "XGBRegressor_model.fit(x_train,y_train)\n",
        "pred\t=\tXGBRegressor_model.predict(x_test)\n",
        "scatter(y_test,\tpred,\tcolor='g')\n",
        "show()\n",
        "\n",
        "Ridge_model.fit(x_train,y_train)\n",
        "pred\t=\tRidge_model.predict(x_test)\n",
        "scatter(y_test,\tpred,\tcolor='g')\n",
        "show()\n",
        "\n",
        "LinearRegression_model.fit(x_train,y_train)\n",
        "pred\t=\tLinearRegression_model.predict(x_test)\n",
        "scatter(y_test,\tpred,\tcolor='g')\n",
        "show()"
      ],
      "metadata": {
        "id": "8fOBdehK-Ik-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7- Conclusion\n",
        "Based\ton\tthese\tevaluation\tmetrics,\tthe\tXGBRegressor\tis\tthe\tsuperior\tmodel\tfor\tthis\tregression\ttask.\tIt demonstrates\tsignificantly\tbetter\tpredictive\tpower\tby\texplaining\tmore\tvariance\tand\tachieving\tlower error\trates\tcompared\tto\tboth\tLinear\tRegression\tand\tRidge.\tThis\tsuggests\tthat\tthe\tunderlying\tdata\tmight have\tnon-linear\trelationships\tthat\tXGBRegressor\tis\tbetter\tequipped\tto\tcapture."
      ],
      "metadata": {
        "id": "aKWzutWl-uMr"
      }
    }
  ]
}